{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af4e2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully\n",
      "Data Loaded:\n",
      "   Training samples: 888\n",
      "   Test samples: 222\n",
      "   Features: 16\n",
      "   Target range: [63.80, 81.80]\n",
      "Model Configurations:\n",
      "   KNN\n",
      "   DECISION_TREE\n",
      "   RANDOM_FOREST\n",
      "   SVR\n",
      "   RIDGE\n",
      "   NEURAL_NETWORK\n",
      "======================================================================\n",
      "TRAINING BASE MODELS WITH 10-FOLD CROSS-VALIDATION\n",
      "======================================================================\n",
      "\n",
      "Training KNN...\n",
      "   KNN Trained\n",
      "      10-Fold CV RMSE: 2.3098 ± 0.8355\n",
      "      Test RMSE: 2.6395\n",
      "      Test MAE: 2.1319\n",
      "      Test R²: 0.0705\n",
      "      Best Params: {'n_neighbors': 9, 'weights': 'distance'}\n",
      "\n",
      "Training DECISION_TREE...\n",
      "   DECISION_TREE Trained\n",
      "      10-Fold CV RMSE: 2.3510 ± 0.8542\n",
      "      Test RMSE: 2.6760\n",
      "      Test MAE: 2.1251\n",
      "      Test R²: 0.0446\n",
      "      Best Params: {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "\n",
      "Training RANDOM_FOREST...\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"All libraries imported successfully\")\n",
    "\n",
    "# Cell 2: Load Preprocessed Data\n",
    "X_train = np.load('../regression_processed_data/X_train.npy')\n",
    "X_test = np.load('../regression_processed_data/X_test.npy')\n",
    "y_train = np.load('../regression_processed_data/y_train.npy')\n",
    "y_test = np.load('../regression_processed_data/y_test.npy')\n",
    "\n",
    "print(f\"Data Loaded:\")\n",
    "print(f\"   Training samples: {X_train.shape[0]}\")\n",
    "print(f\"   Test samples: {X_test.shape[0]}\")\n",
    "print(f\"   Features: {X_train.shape[1]}\")\n",
    "print(f\"   Target range: [{y_train.min():.2f}, {y_train.max():.2f}]\")\n",
    "\n",
    "# Cell 3: Define Model Configurations\n",
    "model_configs = {\n",
    "    'knn': {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'params': {\n",
    "            'n_neighbors': [3, 5, 7, 9],\n",
    "            'weights': ['uniform', 'distance']\n",
    "        }\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'model': DecisionTreeRegressor(random_state=42),\n",
    "        'params': {\n",
    "            'max_depth': [3, 5, 7, 10, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestRegressor(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [5, 10, 15, None],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    'svr': {\n",
    "        'model': SVR(),\n",
    "        'params': {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'epsilon': [0.01, 0.1, 0.2],\n",
    "            'kernel': ['rbf']\n",
    "        }\n",
    "    },\n",
    "    'ridge': {\n",
    "        'model': Ridge(),\n",
    "        'params': {\n",
    "            'alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "        }\n",
    "    },\n",
    "    'neural_network': {\n",
    "        'model': MLPRegressor(random_state=42, max_iter=1000, early_stopping=True),\n",
    "        'params': {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "            'activation': ['relu', 'tanh'],\n",
    "            'alpha': [0.0001, 0.001, 0.01],\n",
    "            'learning_rate': ['constant', 'adaptive']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Model Configurations:\")\n",
    "for name in model_configs.keys():\n",
    "    print(f\"   {name.upper()}\")\n",
    "\n",
    "# Cell 4: Train Models with 10-Fold CV\n",
    "results = {}\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING BASE MODELS WITH 10-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for name, config in model_configs.items():\n",
    "    print(f\"\\nTraining {name.upper()}...\")\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        config['model'],\n",
    "        config['params'],\n",
    "        cv=cv,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    cv_results = grid_search.cv_results_\n",
    "    best_index = grid_search.best_index_\n",
    "    \n",
    "    # Extract fold scores\n",
    "    fold_scores = []\n",
    "    for fold_idx in range(10):\n",
    "        fold_key = f'split{fold_idx}_test_score'\n",
    "        fold_scores.append(-cv_results[fold_key][best_index])\n",
    "    \n",
    "    cv_mean = np.mean(fold_scores)\n",
    "    cv_std = np.std(fold_scores)\n",
    "    cv_min = np.min(fold_scores)\n",
    "    cv_max = np.max(fold_scores)\n",
    "    cv_rmse = np.sqrt(cv_mean)\n",
    "    \n",
    "    # Test predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    test_mse = mean_squared_error(y_test, y_pred)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    test_mae = mean_absolute_error(y_test, y_pred)\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': best_model,\n",
    "        'cv_mse_mean': cv_mean,\n",
    "        'cv_mse_std': cv_std,\n",
    "        'cv_mse_min': cv_min,\n",
    "        'cv_mse_max': cv_max,\n",
    "        'cv_rmse': cv_rmse,\n",
    "        'cv_10fold_scores': fold_scores,\n",
    "        'test_mse': test_mse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mae': test_mae,\n",
    "        'test_r2': test_r2,\n",
    "        'y_pred': y_pred,\n",
    "        'best_params': grid_search.best_params_\n",
    "    }\n",
    "    \n",
    "    print(f\"   {name.upper()} Trained\")\n",
    "    print(f\"      10-Fold CV RMSE: {cv_rmse:.4f} ± {np.sqrt(cv_std):.4f}\")\n",
    "    print(f\"      Test RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"      Test MAE: {test_mae:.4f}\")\n",
    "    print(f\"      Test R²: {test_r2:.4f}\")\n",
    "    print(f\"      Best Params: {grid_search.best_params_}\")\n",
    "\n",
    "# Cell 5: Visualize 10-Fold CV Results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "model_names = list(results.keys())\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c', '#9b59b6', '#f39c12', '#1abc9c']\n",
    "\n",
    "# Plot 1: Box plot of 10-fold scores (RMSE)\n",
    "fold_data = []\n",
    "for name in model_names:\n",
    "    for fold_idx, mse in enumerate(results[name]['cv_10fold_scores'], 1):\n",
    "        fold_data.append({\n",
    "            'Model': name.upper(),\n",
    "            'Fold': fold_idx,\n",
    "            'RMSE': np.sqrt(mse)\n",
    "        })\n",
    "\n",
    "fold_df = pd.DataFrame(fold_data)\n",
    "\n",
    "box_positions = []\n",
    "for idx, name in enumerate(model_names):\n",
    "    model_data = fold_df[fold_df['Model'] == name.upper()]['RMSE']\n",
    "    bp = axes[0, 0].boxplot([model_data], positions=[idx], widths=0.6,\n",
    "                            patch_artist=True,\n",
    "                            boxprops=dict(facecolor=colors[idx], alpha=0.7),\n",
    "                            medianprops=dict(color='black', linewidth=2))\n",
    "    box_positions.append(idx)\n",
    "\n",
    "axes[0, 0].set_xticks(box_positions)\n",
    "axes[0, 0].set_xticklabels([name.upper() for name in model_names], rotation=45, ha='right')\n",
    "axes[0, 0].set_ylabel('RMSE', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_title('10-Fold Cross-Validation RMSE Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Line plot showing each fold's performance\n",
    "for idx, name in enumerate(model_names):\n",
    "    fold_rmse = [np.sqrt(mse) for mse in results[name]['cv_10fold_scores']]\n",
    "    axes[0, 1].plot(range(1, 11), fold_rmse, marker='o', linewidth=2,\n",
    "                   label=name.upper(), color=colors[idx])\n",
    "\n",
    "axes[0, 1].set_xlabel('Fold Number', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('RMSE', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_title('RMSE Across 10 Folds', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "axes[0, 1].set_xticks(range(1, 11))\n",
    "\n",
    "# Plot 3: CV RMSE vs Test RMSE comparison\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "cv_rmse_values = [results[name]['cv_rmse'] for name in model_names]\n",
    "test_rmse_values = [results[name]['test_rmse'] for name in model_names]\n",
    "\n",
    "bars1 = axes[1, 0].bar(x - width/2, cv_rmse_values, width, label='10-Fold CV RMSE',\n",
    "                       color=colors, alpha=0.8)\n",
    "bars2 = axes[1, 0].bar(x + width/2, test_rmse_values, width, label='Test RMSE',\n",
    "                       color=colors, alpha=0.5)\n",
    "\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{height:.2f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "axes[1, 0].set_xlabel('Models', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('RMSE', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_title('10-Fold CV RMSE vs Test RMSE', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xticks(x)\n",
    "axes[1, 0].set_xticklabels([name.upper() for name in model_names], rotation=45, ha='right')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 4: R² Score comparison\n",
    "r2_scores = [results[name]['test_r2'] for name in model_names]\n",
    "\n",
    "bars = axes[1, 1].bar([name.upper() for name in model_names], r2_scores,\n",
    "                      color=colors, alpha=0.8)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "axes[1, 1].set_xlabel('Models', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('R² Score', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_title('R² Score (Higher is Better)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xticklabels([name.upper() for name in model_names], rotation=45, ha='right')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "axes[1, 1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cell 6: Performance Summary Table\n",
    "summary_data = []\n",
    "for name in model_names:\n",
    "    summary_data.append({\n",
    "        'Model': name.upper(),\n",
    "        'CV RMSE': f\"{results[name]['cv_rmse']:.4f}\",\n",
    "        'Test RMSE': f\"{results[name]['test_rmse']:.4f}\",\n",
    "        'Test MAE': f\"{results[name]['test_mae']:.4f}\",\n",
    "        'Test R²': f\"{results[name]['test_r2']:.4f}\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "display(summary_df)\n",
    "\n",
    "best_model_name = min(results.items(), key=lambda x: x[1]['test_rmse'])[0]\n",
    "print(f\"\\nBest Model: {best_model_name.upper()}\")\n",
    "print(f\"   Test RMSE: {results[best_model_name]['test_rmse']:.4f}\")\n",
    "print(f\"   Test R²: {results[best_model_name]['test_r2']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DETAILED TEST RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for name in model_names:\n",
    "    y_pred = results[name]['y_pred']\n",
    "    rmse = results[name]['test_rmse']\n",
    "    mae = results[name]['test_mae']\n",
    "    r2 = results[name]['test_r2']\n",
    "    \n",
    "    print(f\"\\n{name.upper()}\")\n",
    "    print(f\"   Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"   Test MAE:  {mae:.4f}\")\n",
    "    print(f\"   Test R²:   {r2:.4f}\")\n",
    "    print(f\"   10-Fold CV RMSE: {results[name]['cv_rmse']:.4f} ± {results[name]['cv_mse_std']:.4f}\")\n",
    "    \n",
    "    residuals = y_test - y_pred\n",
    "    print(f\"   Mean Residual: {np.mean(residuals):.4f}\")\n",
    "    print(f\"   Std Residual:  {np.std(residuals):.4f}\")\n",
    "\n",
    "# Cell 6.5: Detailed Test Predictions Analysis\n",
    "os.makedirs('../saved_base_models', exist_ok=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TEST PREDICTIONS ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for name in model_names:\n",
    "    y_pred = results[name]['y_pred']\n",
    "    \n",
    "    prediction_details = pd.DataFrame({\n",
    "        'Actual': y_test,\n",
    "        'Predicted': y_pred,\n",
    "        'Error': y_test - y_pred,\n",
    "        'Absolute_Error': np.abs(y_test - y_pred),\n",
    "        'Percent_Error': np.abs((y_test - y_pred) / y_test) * 100\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{name.upper()}\")\n",
    "    print(f\"   Total Test Samples: {len(y_test)}\")\n",
    "    print(f\"   Mean Absolute Error: {prediction_details['Absolute_Error'].mean():.4f}\")\n",
    "    print(f\"   Median Absolute Error: {prediction_details['Absolute_Error'].median():.4f}\")\n",
    "    print(f\"   Max Error: {prediction_details['Absolute_Error'].max():.4f}\")\n",
    "    print(f\"   Min Error: {prediction_details['Absolute_Error'].min():.4f}\")\n",
    "    \n",
    "    print(f\"\\n   First 10 predictions:\")\n",
    "    print(prediction_details.head(10).to_string(index=False))\n",
    "    \n",
    "    csv_file = f'../saved_base_models/{name}_test_predictions.csv'\n",
    "    prediction_details.to_csv(csv_file, index=False)\n",
    "    print(f\"\\n   Saved detailed predictions: {csv_file}\")\n",
    "\n",
    "# Cell 7: Prediction vs Actual Plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, name in enumerate(model_names):\n",
    "    y_pred = results[name]['y_pred']\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[idx].scatter(y_test, y_pred, alpha=0.6, s=50, color=colors[idx])\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val = min(y_test.min(), y_pred.min())\n",
    "    max_val = max(y_test.max(), y_pred.max())\n",
    "    axes[idx].plot([min_val, max_val], [min_val, max_val], \n",
    "                   'r--', linewidth=2, label='Perfect Prediction')\n",
    "    \n",
    "    # Metrics\n",
    "    rmse = results[name]['test_rmse']\n",
    "    r2 = results[name]['test_r2']\n",
    "    \n",
    "    axes[idx].set_xlabel('Actual Exam Score', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Predicted Exam Score', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_title(f'{name.upper()}\\nRMSE: {rmse:.2f}, R²: {r2:.3f}',\n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cell 8: Feature Importance Analysis\n",
    "feature_names = json.load(open('../regression_processed_data/feature_names.json'))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Models that support feature importance\n",
    "tree_based_models = ['decision_tree', 'random_forest']\n",
    "\n",
    "# Dictionary to store feature importance for all models\n",
    "feature_importance_dict = {}\n",
    "\n",
    "# Calculate feature importance for tree-based models\n",
    "for name in tree_based_models:\n",
    "    if name in results:\n",
    "        model = results[name]['model']\n",
    "        importance = model.feature_importances_\n",
    "        \n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': importance\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        feature_importance_dict[name] = feature_importance\n",
    "        \n",
    "        print(f\"\\n{name.upper()} - Top 10 Features:\")\n",
    "        print(feature_importance.head(10).to_string(index=False))\n",
    "\n",
    "# Calculate permutation importance for other models\n",
    "other_models = ['knn', 'svr', 'ridge', 'neural_network']\n",
    "\n",
    "print(\"\\nCalculating permutation importance for remaining models...\")\n",
    "for name in other_models:\n",
    "    if name in results:\n",
    "        print(f\"   Processing {name.upper()}...\")\n",
    "        model = results[name]['model']\n",
    "        \n",
    "        # Calculate permutation importance\n",
    "        perm_importance = permutation_importance(\n",
    "            model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': perm_importance.importances_mean\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        feature_importance_dict[name] = feature_importance\n",
    "        \n",
    "        print(f\"\\n{name.upper()} - Top 10 Features (Permutation Importance):\")\n",
    "        print(feature_importance.head(10).to_string(index=False))\n",
    "\n",
    "# Visualize feature importance for all models\n",
    "num_models = len(feature_importance_dict)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, importance_df) in enumerate(feature_importance_dict.items()):\n",
    "    top_features = importance_df.head(10)\n",
    "    \n",
    "    axes[idx].barh(top_features['Feature'], top_features['Importance'], \n",
    "                   color=colors[idx], edgecolor='black', alpha=0.8)\n",
    "    axes[idx].set_xlabel('Importance', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Features', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    importance_type = \"Feature Importance\" if name in tree_based_models else \"Permutation Importance\"\n",
    "    axes[idx].set_title(f'{name.upper()}\\n{importance_type}', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[idx].invert_yaxis()\n",
    "    axes[idx].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Hide unused subplot\n",
    "if num_models < 6:\n",
    "    for idx in range(num_models, 6):\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save feature importance to CSV\n",
    "print(\"\\nSaving feature importance data...\")\n",
    "for name, importance_df in feature_importance_dict.items():\n",
    "    csv_file = f'../saved_base_models/{name}_feature_importance.csv'\n",
    "    importance_df.to_csv(csv_file, index=False)\n",
    "    print(f\"   Saved: {csv_file}\")\n",
    "\n",
    "# Cell 9: Save Models\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SAVING TRAINED MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for name, data in results.items():\n",
    "    model_path = f'../saved_base_models/{name}_model.pkl'\n",
    "    try:\n",
    "        with open(model_path, 'wb') as f:\n",
    "            joblib.dump(data['model'], f, compress=3)\n",
    "        print(f\"   Saved: {name}_model.pkl\")\n",
    "        \n",
    "        # Verify the saved model\n",
    "        test_load = joblib.load(model_path)\n",
    "        print(f\"   Verified: {name}_model.pkl\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR saving {name}_model.pkl: {e}\")\n",
    "\n",
    "print(\"\\nModels saved to saved_base_models/\")\n",
    "\n",
    "# Cell 10: Create and Save Preprocessor\n",
    "import sys\n",
    "\n",
    "# Ensure saved_ensemble_models directory exists\n",
    "os.makedirs('../saved_ensemble_models', exist_ok=True)\n",
    "\n",
    "models_path = os.path.abspath('..')\n",
    "if models_path not in sys.path:\n",
    "    sys.path.insert(0, models_path)\n",
    "\n",
    "# Import with experimental flag\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from regression_preprocessor import RegressionPreprocessor\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CREATING AND SAVING PREPROCESSOR\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Load the preprocessing components\n",
    "    print(\"\\nLoading preprocessing components...\")\n",
    "    \n",
    "    label_encoders = joblib.load('../regression_processed_data/label_encoders.pkl')\n",
    "    print(\"   Label encoders loaded\")\n",
    "    \n",
    "    iterative_imputer = joblib.load('../regression_processed_data/iterative_imputer.pkl')\n",
    "    print(\"   Iterative imputer loaded\")\n",
    "    \n",
    "    median_imputer = joblib.load('../regression_processed_data/median_imputer.pkl')\n",
    "    print(\"   Median imputer loaded\")\n",
    "    \n",
    "    scaler = joblib.load('../regression_processed_data/scaler.pkl')\n",
    "    print(\"   Scaler loaded\")\n",
    "    \n",
    "    with open('../regression_processed_data/feature_names.json', 'r') as f:\n",
    "        feature_names = json.load(f)\n",
    "    print(\"   Feature names loaded\")\n",
    "    \n",
    "    with open('../regression_processed_data/imputation_config.json', 'r') as f:\n",
    "        imputation_config = json.load(f)\n",
    "    print(\"   Imputation config loaded\")\n",
    "    \n",
    "    # Create preprocessor with both imputers\n",
    "    print(\"\\nCreating preprocessor object...\")\n",
    "    preprocessor = RegressionPreprocessor(\n",
    "        iterative_imputer=iterative_imputer,\n",
    "        median_imputer=median_imputer,\n",
    "        label_encoders=label_encoders,\n",
    "        scaler=scaler,\n",
    "        imputation_config=imputation_config\n",
    "    )\n",
    "    print(f\"   Created: {preprocessor}\")\n",
    "    \n",
    "    # Save preprocessor\n",
    "    print(\"\\nSaving preprocessor...\")\n",
    "    preprocessor_path = '../regression_processed_data/preprocessor.pkl'\n",
    "    \n",
    "    with open(preprocessor_path, 'wb') as f:\n",
    "        joblib.dump(preprocessor, f, compress=3)\n",
    "    \n",
    "    # Verify the save was successful\n",
    "    file_size = os.path.getsize(preprocessor_path)\n",
    "    print(f\"   Preprocessor saved: {preprocessor_path}\")\n",
    "    print(f\"   File size: {file_size} bytes\")\n",
    "    \n",
    "    # Test loading the preprocessor\n",
    "    print(\"\\nVerifying saved preprocessor...\")\n",
    "    test_load = joblib.load(preprocessor_path)\n",
    "    print(f\"   Preprocessor verified: {test_load}\")\n",
    "    print(f\"   Feature names count: {len(test_load.get_feature_names())}\")\n",
    "    \n",
    "    # Save feature names\n",
    "    feature_names_path = '../regression_processed_data/feature_names.pkl'\n",
    "    with open(feature_names_path, 'wb') as f:\n",
    "        joblib.dump(feature_names, f, compress=3)\n",
    "    print(f\"   Feature names saved: {feature_names_path}\")\n",
    "    \n",
    "    # Save imputation config copy\n",
    "    config_path = '../regression_processed_data/imputation_config.json'\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(imputation_config, f, indent=2)\n",
    "    print(f\"   Imputation config saved: {config_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"FILES CREATED:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"   {preprocessor_path} ({os.path.getsize(preprocessor_path)} bytes)\")\n",
    "    print(f\"   {feature_names_path} ({os.path.getsize(feature_names_path)} bytes)\")\n",
    "    print(f\"   {config_path}\")\n",
    "    print(\"\\nPreprocessor creation complete\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"BASE MODELS TRAINING COMPLETE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nERROR: Required file not found: {e}\")\n",
    "    print(\"\\nPlease run the preprocessing notebook first to generate:\")\n",
    "    print(\"   - regression_processed_data/imputation_config.json\")\n",
    "    print(\"   - regression_processed_data/label_encoders.pkl\")\n",
    "    print(\"   - regression_processed_data/scaler.pkl\")\n",
    "    print(\"   - regression_processed_data/feature_names.json\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nERROR: Failed to create preprocessor: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
