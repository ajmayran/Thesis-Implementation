{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0167d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, BaggingClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "\n",
    "# Cell 2: Define EnsembleModels Class\n",
    "class EnsembleModels:\n",
    "    def __init__(self, best_params_dict=None):\n",
    "        self.best_params = best_params_dict or {}\n",
    "        self.ensemble_models = {}\n",
    "        self.y_test = None\n",
    "        \n",
    "    def create_bagging_ensemble(self):\n",
    "        bagging = BaggingClassifier(\n",
    "            estimator=RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=15,\n",
    "                min_samples_split=5,\n",
    "                random_state=42\n",
    "            ),\n",
    "            n_estimators=15,\n",
    "            max_samples=0.7,\n",
    "            max_features=0.9,\n",
    "            bootstrap=True,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        self.ensemble_models['bagging'] = bagging\n",
    "        print(\"[INFO] Bagging: 15 Random Forests with 70% samples\")\n",
    "        return bagging\n",
    "    \n",
    "    def create_boosting_ensemble(self):\n",
    "        boosting = GradientBoostingClassifier(\n",
    "            n_estimators=150,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=4,\n",
    "            min_samples_split=5,\n",
    "            subsample=0.8,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.ensemble_models['boosting'] = boosting\n",
    "        print(\"[INFO] Boosting: 150 estimators, LR=0.05, depth=4\")\n",
    "        return boosting\n",
    "\n",
    "    def create_xgboost_ensemble(self):\n",
    "        xgboost_model = XGBClassifier(\n",
    "            n_estimators=150,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=4,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.9,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        self.ensemble_models['xgboost'] = xgboost_model\n",
    "        print(\"[INFO] XGBoost: 150 estimators, LR=0.05, depth=4\")\n",
    "        return xgboost_model\n",
    "    \n",
    "    def create_stacking_ensemble(self):\n",
    "        rf_params = self.best_params.get('random_forest', {'n_estimators': 100, 'max_depth': 15})\n",
    "        svm_params = self.best_params.get('svm', {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale'})\n",
    "        dt_params = self.best_params.get('decision_tree', {'max_depth': 10, 'min_samples_split': 5})\n",
    "        \n",
    "        estimators = [\n",
    "            ('random_forest', RandomForestClassifier(random_state=42, **rf_params)),\n",
    "            ('svm', SVC(probability=True, random_state=42, **svm_params)),\n",
    "            ('decision_tree', DecisionTreeClassifier(random_state=42, **dt_params))\n",
    "        ]\n",
    "        \n",
    "        print(f\"[INFO] Selective Stacking: Using only top 3 performing base models:\")\n",
    "        for name, _ in estimators:\n",
    "            print(f\"   - {name.replace('_', ' ').upper()}\")\n",
    "        \n",
    "        stacking = StackingClassifier(\n",
    "            estimators=estimators,\n",
    "            final_estimator=LogisticRegression(random_state=42, max_iter=1000),\n",
    "            cv=5,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        self.ensemble_models['stacking'] = stacking\n",
    "        return stacking\n",
    "\n",
    "    def create_weighted_voting_ensemble(self):\n",
    "        rf_params = self.best_params.get('random_forest', {'n_estimators': 100, 'max_depth': 15})\n",
    "        svm_params = self.best_params.get('svm', {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale'})\n",
    "        dt_params = self.best_params.get('decision_tree', {'max_depth': 10, 'min_samples_split': 5})\n",
    "        \n",
    "        estimators = [\n",
    "            ('random_forest', RandomForestClassifier(random_state=42, **rf_params)),\n",
    "            ('svm', SVC(probability=True, random_state=42, **svm_params)),\n",
    "            ('decision_tree', DecisionTreeClassifier(random_state=42, **dt_params))\n",
    "        ]\n",
    "        \n",
    "        voting = VotingClassifier(\n",
    "            estimators=estimators,\n",
    "            voting='soft',\n",
    "            weights=[2, 1.5, 1],\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        self.ensemble_models['weighted_voting'] = voting\n",
    "        print(\"[INFO] Weighted Voting: RF(2.0), SVM(1.5), DT(1.0)\")\n",
    "        return voting\n",
    "    \n",
    "    def train_ensemble_models_with_10fold(self, X_train, y_train, X_test, y_test):\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"[ENSEMBLE] TRAINING ENSEMBLE MODELS WITH 10-FOLD CV\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        self.y_test = y_test\n",
    "        results = {}\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        \n",
    "        print(\"\\n[CREATE] Creating ensemble models...\")\n",
    "        self.create_bagging_ensemble()\n",
    "        self.create_boosting_ensemble()\n",
    "        self.create_xgboost_ensemble()\n",
    "        self.create_stacking_ensemble()\n",
    "        self.create_weighted_voting_ensemble()\n",
    "        \n",
    "        for name, model in self.ensemble_models.items():\n",
    "            print(f\"\\n[MODEL] Training {name.upper()} with 10-fold CV on TRAINING SET ONLY...\")\n",
    "            \n",
    "            fold_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "            \n",
    "            cv_mean = np.mean(fold_scores)\n",
    "            cv_std = np.std(fold_scores)\n",
    "            cv_min = np.min(fold_scores)\n",
    "            cv_max = np.max(fold_scores)\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "            \n",
    "            test_accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            auc_roc = 0\n",
    "            if y_pred_proba is not None:\n",
    "                fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "                auc_roc = auc(fpr, tpr)\n",
    "            \n",
    "            results[name] = {\n",
    "                'accuracy': test_accuracy,\n",
    "                'cv_10fold_mean': cv_mean,\n",
    "                'cv_10fold_std': cv_std,\n",
    "                'cv_10fold_min': cv_min,\n",
    "                'cv_10fold_max': cv_max,\n",
    "                'cv_10fold_scores': fold_scores.tolist(),\n",
    "                'auc_roc': auc_roc,\n",
    "                'classification_report': classification_report(y_test, y_pred, output_dict=True),\n",
    "                'confusion_matrix': confusion_matrix(y_test, y_pred).tolist(),\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba\n",
    "            }\n",
    "            \n",
    "            print(f\"   > CV Accuracy: {cv_mean:.4f} (+/- {cv_std:.4f})\")\n",
    "            print(f\"   > Test Accuracy: {test_accuracy:.4f}\")\n",
    "            print(f\"   > AUC-ROC: {auc_roc:.4f}\")\n",
    "\n",
    "        self._save_results_to_json(results, 'ensemble_comparison/ensemble_models_results.json')\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _save_results_to_json(self, results, filepath):\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        \n",
    "        class NumpyEncoder(json.JSONEncoder):\n",
    "            def default(self, obj):\n",
    "                if isinstance(obj, np.integer):\n",
    "                    return int(obj)\n",
    "                if isinstance(obj, np.floating):\n",
    "                    return float(obj)\n",
    "                if isinstance(obj, np.ndarray):\n",
    "                    return obj.tolist()\n",
    "                return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "        json_results = {}\n",
    "        for name, result in results.items():\n",
    "            json_results[name] = {k: v for k, v in result.items() \n",
    "                                if k not in ['y_pred', 'y_pred_proba', 'confusion_matrix']}\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(json_results, f, indent=2, cls=NumpyEncoder)\n",
    "        \n",
    "        print(f\"[SAVED] Ensemble results saved to {filepath}\")\n",
    "\n",
    "    def visualize_10fold_results(self, results, output_dir='ensemble_comparison'):\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        sns.set_style(\"whitegrid\")\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        model_names = list(results.keys())\n",
    "        colors = ['#f59e0b', '#10b981', '#3b82f6', '#8b5cf6', '#ef4444'] \n",
    "        \n",
    "        fold_data = []\n",
    "        for name in model_names:\n",
    "            for fold_idx, score in enumerate(results[name]['cv_10fold_scores'], 1):\n",
    "                fold_data.append({\n",
    "                    'Model': name.upper(),\n",
    "                    'Fold': fold_idx,\n",
    "                    'Accuracy': score\n",
    "                })\n",
    "        \n",
    "        fold_df = pd.DataFrame(fold_data)\n",
    "        \n",
    "        sns.boxplot(x='Model', y='Accuracy', data=fold_df, ax=axes[0, 0], palette=colors[:len(model_names)])\n",
    "        axes[0, 0].set_xticklabels([name.upper() for name in model_names], rotation=15, ha='right')\n",
    "        axes[0, 0].set_title('10-Fold Cross-Validation Score Distribution', fontsize=14, fontweight='bold')\n",
    "        axes[0, 0].set_ylim([0.0, 1.0])\n",
    "        \n",
    "        for idx, name in enumerate(model_names):\n",
    "            model_data = fold_df[fold_df['Model'] == name.upper()]\n",
    "            axes[0, 1].plot(model_data['Fold'], model_data['Accuracy'], marker='o', \n",
    "                           label=name.upper(), color=colors[idx % len(colors)])\n",
    "        \n",
    "        axes[0, 1].set_title('Accuracy Across 10 Folds', fontsize=14, fontweight='bold')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].set_ylim([0.0, 1.0])\n",
    "        \n",
    "        x = np.arange(len(model_names))\n",
    "        width = 0.35\n",
    "        \n",
    "        cv_means = [results[name]['cv_10fold_mean'] for name in model_names]\n",
    "        test_accs = [results[name]['accuracy'] for name in model_names]\n",
    "        \n",
    "        axes[1, 0].bar(x - width/2, cv_means, width, label='10-Fold CV Mean', color='#3b82f6', alpha=0.8)\n",
    "        axes[1, 0].bar(x + width/2, test_accs, width, label='Test Accuracy', color='#10b981', alpha=0.8)\n",
    "        \n",
    "        axes[1, 0].set_title('10-Fold CV Mean vs Test Accuracy', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_xticks(x)\n",
    "        axes[1, 0].set_xticklabels([name.upper() for name in model_names], rotation=15, ha='right')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].set_ylim([0.0, 1.0])\n",
    "        \n",
    "        cv_stds = [results[name]['cv_10fold_std'] for name in model_names]\n",
    "        axes[1, 1].bar([name.upper() for name in model_names], cv_stds, color=colors[:len(model_names)], alpha=0.8)\n",
    "        axes[1, 1].set_title('10-Fold CV Standard Deviation (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].set_xticklabels([name.upper() for name in model_names], rotation=15, ha='right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def print_10fold_summary(self, results):\n",
    "        print(\"\\n\" + \"=\"*90)\n",
    "        print(\"ENSEMBLE 10-FOLD CROSS-VALIDATION SUMMARY\")\n",
    "        print(\"=\"*90)\n",
    "        \n",
    "        print(f\"\\n{'Model':<20} {'CV Mean':<12} {'CV Std':<12} {'CV Min':<12} {'CV Max':<12} {'Test Acc':<12}\")\n",
    "        print(\"-\"*90)\n",
    "        \n",
    "        sorted_results = sorted(results.items(), key=lambda x: x[1]['cv_10fold_mean'], reverse=True)\n",
    "        \n",
    "        for name, result in sorted_results:\n",
    "            print(f\"{name.upper():<20} {result['cv_10fold_mean']:.4f}       {result['cv_10fold_std']:.4f}       {result['cv_10fold_min']:.4f}       {result['cv_10fold_max']:.4f}       {result['accuracy']:.4f}\")\n",
    "\n",
    "# Cell 3: Load Data and Run Training\n",
    "\n",
    "DATA_DIR = 'classification_processed_data'\n",
    "RESULTS_FILE = 'model_comparison/base_models_results.json'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"[START] TRAINING ENSEMBLE MODELS WITH 10-FOLD CV\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    X_train = np.load(os.path.join(DATA_DIR, 'X_train_label.npy'))\n",
    "    X_test = np.load(os.path.join(DATA_DIR, 'X_test_label.npy'))\n",
    "    y_train = np.load(os.path.join(DATA_DIR, 'y_train.npy'))\n",
    "    y_test = np.load(os.path.join(DATA_DIR, 'y_test.npy'))\n",
    "    print(f\"[INFO] Data loaded successfully from {DATA_DIR}\")\n",
    "    print(f\"   Training samples: {X_train.shape[0]}\")\n",
    "    print(f\"   Test samples: {X_test.shape[0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Could not load data: {e}\")\n",
    "    raise e\n",
    "\n",
    "best_params = {}\n",
    "if os.path.exists(RESULTS_FILE):\n",
    "    try:\n",
    "        with open(RESULTS_FILE, 'r') as f:\n",
    "            results_data = json.load(f)\n",
    "            for model_name, model_data in results_data.items():\n",
    "                if 'best_params' in model_data:\n",
    "                    best_params[model_name] = model_data['best_params']\n",
    "        print(f\"[INFO] Loaded hyperparameters for {len(best_params)} base models\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Error loading results file: {e}\")\n",
    "else:\n",
    "    print(\"[WARNING] No base model results file found, using default hyperparameters\")\n",
    "\n",
    "ensemble = EnsembleModels(best_params_dict=best_params)\n",
    "ensemble_results = ensemble.train_ensemble_models_with_10fold(X_train, y_train, X_test, y_test)\n",
    "\n",
    "ensemble.print_10fold_summary(ensemble_results)\n",
    "\n",
    "# Cell 4: Visualize Results and Save Models\n",
    "\n",
    "print(f\"\\n[VISUALIZATION] Creating 10-fold CV analysis...\")\n",
    "ensemble.visualize_10fold_results(ensemble_results)\n",
    "\n",
    "SAVE_DIR = 'saved_classification_ensemble_models'\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "for name, model in ensemble.ensemble_models.items():\n",
    "    joblib.dump(model, os.path.join(SAVE_DIR, f'{name}_ensemble.pkl'))\n",
    "\n",
    "print(f\"\\n[SAVE] Ensemble models saved to {SAVE_DIR}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
